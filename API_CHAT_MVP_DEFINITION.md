# API Endpoint: `/assistant/chat`

This document describes the server-side API for the `/assistant/chat` endpoint and defines the scope for the Chatting MVP.

## 1. API Endpoint: `/assistant/chat`

*   **Method:** `POST`
*   **Authentication:** Required (e.g., via JWT in Authorization header/cookie - *specific mechanism to be confirmed based on actual server implementation*).
*   **Request Body:**
    The client must send a JSON object with the following properties:

    *   `message` (string, required): The user's chat message.
    *   `location` (object, required): User's current geographical location. This is used as the default location for services like weather.
        *   `latitude` (number, required): The latitude coordinate.
        *   `longitude` (number, required): The longitude coordinate.

*   **Example Request Body:**

    ```json
    {
      "message": "What's the weather like here for tomorrow?",
      "location": {
        "latitude": 34.0522,
        "longitude": -118.2437
      }
    }
    ```

## 2. Server Responses

### Success Response (HTTP 200 OK)

*   **Content-Type:** `application/json`
*   **Body Structure:**
    The server returns a standardized JSON object. The key fields are:

    *   `intent` (string): The primary intent determined by the `controlTower` (e.g., "weather_question", "general_question", "schedule_report", "system_error").
    *   `response` (string): The richly formatted text response generated by `mainAssistant`. This text may contain markdown elements such as headings (e.g., `## Weather Details`), bullet points (e.g., `* Sunny with a chance of clouds.`), and bold text for emphasis. The client should be prepared to render this markdown.
    *   `formatType` (string): A hint for the client UI on how to best display the `response` and `rawData`. Example values include:
        *   `"text"`: General text-based response.
        *   `"weather_report"`: The `rawData` contains detailed weather information.
        *   `"schedule_list"`: The `rawData` contains a list of schedule items.
        *   `"schedule_recommendation_list"`: The `rawData` contains schedule suggestions.
        *   `"research_summary"`: The `rawData` contains a research summary.
        *   `"search_results_list"`: The `rawData` contains web search results.
        *   `"confirmation_message"`: Response is a confirmation of an action.
        *   `"error"`: The response is a user-friendly error message; `rawData` will contain `errorContext`.
    *   `rawData` (object): An object containing additional data that the client might use for richer UI rendering or for context. Its structure depends on the `formatType`:
        *   If the response is a direct answer from `mainAssistant` or a simple tool response formatted by `mainAssistant`, `rawData` typically contains `assistantAnalysis` (which includes fields like `summary`, `user_intent_summary`, `next_step`, `metadata` from `mainAssistant`'s own structured output).
        *   If `mainAssistant` is presenting data from a prior model (e.g., `weatherService`, `researchModel`, `scheduleAssistant`), `rawData` will contain:
            *   `sourceData` (object, optional): The direct, structured output from the preceding model/service (e.g., the array of hourly weather data, or the structured research findings).
            *   `assistantAnalysis` (object, optional): Metadata from `mainAssistant` about its presentation (e.g., `summary`, `next_step`).
        *   If `formatType` is `"error"` and the error was handled gracefully by the AI flow, `rawData` will contain:
            *   `errorContext` (object, optional): Details about the error that occurred (e.g., `flowName`, `message` from the `errorEncountered` object passed to `mainAssistant`).
            *   `assistantAnalysis` (object, optional): Metadata from `mainAssistant` about its error presentation.
    *   `modelUsed` (string): The primary AI model that generated the final response, typically `"mainAssistant"`.
    *   `toolUsed` (string | null): If a specific tool was central to the flow (e.g., "weatherService"), its name might be included here. Often `null` if `mainAssistant` is orchestrating or directly answering.

*   **Example Success Response Body (Weather Report):**

    ```json
    {
      "intent": "weather_question",
      "response": "Okay, here's the weather for your current location for the next 2 days:\n\n## Day 1: (YYYY-MM-DD)\n*   Morning: Sunny, 15°C (feels like 14°C), 30% humidity, 0% chance of rain.\n*   Afternoon: Clear skies, 20°C (feels like 19°C), 25% humidity, 0% chance of rain.\n\n## Day 2: (YYYY-MM-DD)\n*   Morning: Partly cloudy, 16°C (feels like 15°C), 40% humidity, 10% chance of rain.",
      "formatType": "weather_report",
      "rawData": {
        "sourceData": [
          { "datetime": "YYYY-MM-DD 09:00", "condition": "Sunny", "temperature": "15°C (feels like 14°C)", "humidity": "30%", "chance_of_rain": "0%", "chance_of_snow": "0%", "wind": "5 kph from NW", "uv_index": 3 },
          { "datetime": "YYYY-MM-DD 14:00", "condition": "Clear skies", "temperature": "20°C (feels like 19°C)", "humidity": "25%", "chance_of_rain": "0%", "chance_of_snow": "0%", "wind": "7 kph from W", "uv_index": 5 },
          { "datetime": "YYYY-MM-DD+1 09:00", "condition": "Partly cloudy", "temperature": "16°C (feels like 15°C)", "humidity": "40%", "chance_of_rain": "10%", "chance_of_snow": "0%", "wind": "6 kph from NNW", "uv_index": 3 }
        ],
        "assistantAnalysis": {
          "summary": "Provided a 2-day weather forecast for the user's current location.",
          "user_intent_summary": "User asked for the weather for the next 2 days.",
          "next_step": {
            "suggestion": "Maybe check your schedule for outdoor activities?",
            "type": "suggestion"
          },
          "metadata": {
            "topic": "weather",
            "tone": "helpful"
          }
        }
      },
      "modelUsed": "mainAssistant",
      "toolUsed": "weatherService"
    }
    ```

*   **Example Success Response Body (Graceful Error Presentation by AI):**

    ```json
    {
      "intent": "weather_question",
      "response": "I'm terribly sorry, but it seems I encountered a hiccup while trying to fetch the weather for your location. The weather service might be temporarily unavailable. Could you please try again in a few moments?",
      "formatType": "error",
      "rawData": {
        "errorContext": {
          "flowName": "weatherQuestion",
          "message": "Simulated API failure from weatherService." 
        },
        "assistantAnalysis": {
          "summary": "Informed user about an error fetching weather.",
          "user_intent_summary": "User asked for weather, but an error occurred.",
          "next_step": {
            "suggestion": "Try the request again in a few minutes.",
            "type": "question"
          },
          "metadata": {
            "topic": "system_error",
            "tone": "empathetic"
          }
        }
      },
      "modelUsed": "mainAssistant",
      "toolUsed": null
    }
    ```

### Error Response (HTTP 4xx/5xx)

These are typically errors that occur outside the main AI processing flow, such as authentication failures, malformed requests caught by the server framework, or unhandled exceptions in the server's core request/response pipeline.

*   **Content-Type:** `application/json`
*   **Body Structure (Example for general server errors from `server.js` middleware):**

    ```json
    {
      "success": false,
      "data": null,
      "message": "A human-readable error message describing the issue (e.g., 'Authentication failed', 'Internal Server Error')."
    }
    ```
*   **Example General Error Response Body (e.g., HTTP 500):**

    ```json
    {
      "success": false,
      "data": null,
      "message": "Internal Server Error"
    }
    ```

**Note:** If an error is caught and handled gracefully within an AI flow (e.g., a tool fails but the `catch` block in `handleAiService.js` processes it), the system will attempt to return an HTTP 200 OK response with `formatType: "error"`, where `mainAssistant` explains the issue to the user in a friendly way, as detailed in the Success Response section. The 4xx/5xx responses are for more fundamental request/server issues.

## 3. Chatting MVP Definition (Server-Side)

### Core Functionality:

*   Receive user `message` and `location` (latitude, longitude) via the `/assistant/chat` POST endpoint.
*   Authenticate the user (details TBD, assumed to be handled before hitting the core chat logic).
*   The `controlTower` AI model analyzes the user's message and the provided `userMetaData` (which includes the request's `location` and potentially extracted parameters like `days` for weather) to determine a single primary user intent and the corresponding flow (e.g., `weatherQuestion`, `generalQuestion`).
*   The `handleAiService` executes the determined flow from the `flowMap`. This involves orchestrating calls to specific tools (e.g., `weatherService`) and/or other AI models (e.g., `scheduleAssistant`, `researchModel`).
*   **Unified Exit Point:** All AI-driven flows (including those that handle errors internally) channel their final output through `mainAssistant`. This ensures a consistent tone, persona, and response structure.
*   `mainAssistant` generates a conversational `response` string. This response can be richly formatted using markdown (e.g., headings, bullet points, bolding) to enhance readability.
*   `mainAssistant` determines an appropriate `formatType` string (e.g., "text", "weather_report", "error") as a hint for UI rendering.
*   When `mainAssistant` is presenting data from a preceding model/service or an error context, this original data (`sourceData` or `errorContext` respectively) is included in the `rawData` field of the final response, alongside `mainAssistant`'s own `assistantAnalysis` (which contains its summary, next step suggestions, etc.).
*   A single, standardized JSON response object (as detailed in "Success Response" section) is returned to the client for all successful operations and gracefully handled errors.
*   Basic conversational context (short-term memory) is maintained by `mainAssistant` (via its `chat` object) across turns within a single server-side session.
*   Robust error handling is implemented for common failure points within the AI flows (e.g., tool failures, API issues). These errors are caught, and `mainAssistant` is used to present a user-friendly message with `formatType: "error"`.

### Supported Flows for MVP:

*   **`generalQuestion`**: Direct question-and-answer with `mainAssistant`. `mainAssistant` uses its general knowledge and conversational abilities.
*   **`weatherQuestion`**: Fetches weather information using `weatherService`.
    *   Supports a `days` parameter (1-3) extracted by `controlTower` from user input (e.g., "weather for 3 days") or defaulted.
    *   Supports using the user's provided current `location` or specific coordinates extracted by `controlTower`.
*   **`generalQuestionWithWebSearch`** (Optional, if stable): For questions where `controlTower` deems web search necessary. Uses `webSearch` tool and `mainAssistant` to synthesize/present.
*   **`researchTask`** (Optional, if stable): For more in-depth research queries using the `researchModel` pipeline, with `mainAssistant` presenting the findings.
*   **Basic Error Presentation**: All supported flows, when encountering an error, will route through `mainAssistant` to provide a user-friendly error message with `formatType: "error"`.

*(Note: Stability and completeness of optional flows like web search, research, or schedule interactions will determine their final inclusion in MVP.)*

### Out of Scope for MVP (Examples):

*   **Multiple Intent Handling by `handleUserChat`**: The `handleUserChat` function will process only the first task determined by `controlTower` for the MVP. Support for executing and aggregating results from multiple simultaneous tasks/flows is deferred.
*   **Persistent Cross-Session Memory**: Conversational memory is limited to the current server session with `mainAssistant`. No long-term storage or retrieval of past conversations across different sessions.
*   **Deep Personalization**: Beyond using the provided `location` in `userMetaData` and basic session context, no deep user profile integration or personalization will be implemented in the MVP.
*   **Advanced Client-Side UI Rendering**: The server provides `formatType` and `rawData`. The client-side MVP might implement rich rendering for only a subset of these types (e.g., basic text, markdown for `response`, and perhaps a simple display for `weather_report`). Full rich UI for all `formatType` values and complex `rawData` is not an MVP requirement for the server to function.
*   **Complex Tool Chaining/Agentic Behavior**: Flows are relatively straightforward. Highly complex, multi-step, agentic tool chaining is not part of MVP.
*   **Proactive Notifications/Background Tasks**: The assistant only responds to direct user chat messages.
